{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom nltk.corpus import stopwords\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset, random_split","metadata":{"execution":{"iopub.status.busy":"2023-12-14T01:34:05.366088Z","iopub.execute_input":"2023-12-14T01:34:05.367044Z","iopub.status.idle":"2023-12-14T01:34:13.886146Z","shell.execute_reply.started":"2023-12-14T01:34:05.367004Z","shell.execute_reply":"2023-12-14T01:34:13.885086Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\nsubmission = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv')\norg_train = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_essays.csv')\nextra = pd.read_csv(\"/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\", sep=',')","metadata":{"execution":{"iopub.status.busy":"2023-12-14T01:25:58.969962Z","iopub.execute_input":"2023-12-14T01:25:58.970391Z","iopub.status.idle":"2023-12-14T01:26:00.243209Z","shell.execute_reply.started":"2023-12-14T01:25:58.970341Z","shell.execute_reply":"2023-12-14T01:26:00.241869Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# drop duplicates\nextra = extra.drop_duplicates(subset=['text'])\nextra.reset_index(drop=True, inplace=True)\n\n# Text Preprocessing\nstop_words = set(stopwords.words('english'))\n\ndef clean_text(text):\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuations\n    words = text.split()  # Tokenize\n    words = [word.lower() for word in words if word.isalpha()]  # Lowercase and remove non-alphabetic words\n    words = [word for word in words if word not in stop_words]  # Remove stop words\n    return ' '.join(words)\n\nextra['clean_text'] = extra['text'].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T01:26:00.245742Z","iopub.execute_input":"2023-12-14T01:26:00.246645Z","iopub.status.idle":"2023-12-14T01:26:08.531984Z","shell.execute_reply.started":"2023-12-14T01:26:00.246600Z","shell.execute_reply":"2023-12-14T01:26:08.530959Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# split into train, test, and val set\nextra = extra.sample(frac=1.0, random_state=42).reset_index(drop=True)\ntrain, val = train_test_split(extra, test_size=0.2, random_state=42, stratify=extra['label'])\nX_train, X_val, y_train, y_val = train_test_split(extra['clean_text'], extra['label'], test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T01:26:08.533153Z","iopub.execute_input":"2023-12-14T01:26:08.533491Z","iopub.status.idle":"2023-12-14T01:26:08.605988Z","shell.execute_reply.started":"2023-12-14T01:26:08.533461Z","shell.execute_reply":"2023-12-14T01:26:08.604921Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Tokenization and Encoding for BERT\ntokenizer = BertTokenizer.from_pretrained(\n    'bert-base-uncased', do_lower_case=True, padding=True, truncation=True, max_length=128\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T01:26:27.363956Z","iopub.execute_input":"2023-12-14T01:26:27.364536Z","iopub.status.idle":"2023-12-14T01:26:30.777791Z","shell.execute_reply.started":"2023-12-14T01:26:27.364500Z","shell.execute_reply":"2023-12-14T01:26:30.776650Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71bb475cf118402cbd2c6e9857bc1b2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97eafdcd75ba4ace82c530ceeb650ba1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98d3d18b820f4d26b7d2c5d8e3682f51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d38a980aa4244e3ebb0fc0aefbcce81b"}},"metadata":{}}]},{"cell_type":"code","source":"encoded_train = tokenizer(X_train.tolist(), padding=True, truncation=True, return_tensors='pt')\nencoded_val = tokenizer(X_val.tolist(), padding=True, truncation=True, return_tensors='pt')","metadata":{"execution":{"iopub.status.busy":"2023-12-14T01:26:44.391344Z","iopub.execute_input":"2023-12-14T01:26:44.391763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert labels to tensors\ntrain_labels = torch.tensor(y_train.values)\nval_labels = torch.tensor(y_val.values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create TensorDatasets\ntrain_dataset = TensorDataset(encoded_train['input_ids'], encoded_train['attention_mask'], train_labels)\nval_dataset = TensorDataset(encoded_val['input_ids'], encoded_val['attention_mask'], val_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DataLoader for efficient processing\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the BERT model for sequence classification\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define optimizer and learning rate scheduler\noptimizer = AdamW(model.parameters(), lr=3e-4, correct_bias=False)\nepochs = 10","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training loop\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n\n    for batch in train_loader:\n        input_ids, attention_mask, labels = batch\n        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        total_loss += loss.item()\n\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping to avoid exploding gradients\n        optimizer.step()\n\n    avg_train_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss:.2f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Validation loop\nmodel.eval()\nval_preds = []\nval_labels = []\n\nwith torch.no_grad():\n    for batch in val_loader:\n        input_ids, attention_mask, labels = batch\n        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n\n        val_preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n        val_labels.extend(labels.cpu().numpy())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate validation accuracy\nval_accuracy = accuracy_score(val_labels, val_preds)\nprint(f\"Validation Accuracy: {val_accuracy:.2f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test data processing\ntest_inputs = tokenizer(test_essays['text'].tolist(), padding=True, truncation=True, return_tensors='pt')\n\n# Move input tensor to the same device as the model\ntest_inputs = {key: value.to(device) for key, value in test_inputs.items()}\n\n# Generate predictions using your trained model\nwith torch.no_grad():\n    outputs = model(**test_inputs)\n    logits = outputs.logits\n\n# Assuming the first column of logits corresponds to the negative class (non-AI-generated) \n# and the second column corresponds to the positive class (AI-generated)\npredictions = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()  # Move predictions back to CPU\n\n# Create a submission DataFrame with essay IDs and corresponding predictions\nsubmission = pd.DataFrame({\n    'id': test_essays['id'],\n    'generated': predictions\n})\n\n# Save the submission DataFrame to a CSV file\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}