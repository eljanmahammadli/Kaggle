{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":61542,"databundleVersionId":6888007,"sourceType":"competition"},{"sourceId":6865136,"sourceType":"datasetVersion","datasetId":3945154},{"sourceId":6890527,"sourceType":"datasetVersion","datasetId":3942644},{"sourceId":6901341,"sourceType":"datasetVersion","datasetId":3960967},{"sourceId":6977472,"sourceType":"datasetVersion","datasetId":4005256}],"dockerImageVersionId":30588,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nimport gc\n\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nimport numpy as np\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom tokenizers import (\n    decoders,\n    models,\n    normalizers,\n    pre_tokenizers,\n    processors,\n    trainers,\n    Tokenizer,\n)\n\nfrom datasets import Dataset\nfrom tqdm.auto import tqdm\nfrom transformers import PreTrainedTokenizerFast\n\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import VotingClassifier","metadata":{"execution":{"iopub.status.busy":"2023-12-13T19:56:18.454994Z","iopub.execute_input":"2023-12-13T19:56:18.455239Z","iopub.status.idle":"2023-12-13T19:56:28.405582Z","shell.execute_reply.started":"2023-12-13T19:56:18.455213Z","shell.execute_reply":"2023-12-13T19:56:28.404577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\nsub = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv')\norg_train = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_essays.csv')\ntrain = pd.read_csv(\"/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\", sep=',')","metadata":{"execution":{"iopub.status.busy":"2023-12-13T19:56:28.407889Z","iopub.execute_input":"2023-12-13T19:56:28.408994Z","iopub.status.idle":"2023-12-13T19:56:30.791228Z","shell.execute_reply.started":"2023-12-13T19:56:28.408954Z","shell.execute_reply":"2023-12-13T19:56:30.790227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.drop_duplicates(subset=['text'])\ntrain.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T19:56:30.792481Z","iopub.execute_input":"2023-12-13T19:56:30.792802Z","iopub.status.idle":"2023-12-13T19:56:30.866849Z","shell.execute_reply.started":"2023-12-13T19:56:30.792774Z","shell.execute_reply":"2023-12-13T19:56:30.865894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LOWERCASE = False\nVOCAB_SIZE = 30522","metadata":{"execution":{"iopub.status.busy":"2023-12-13T19:56:30.868875Z","iopub.execute_input":"2023-12-13T19:56:30.869197Z","iopub.status.idle":"2023-12-13T19:56:30.878004Z","shell.execute_reply.started":"2023-12-13T19:56:30.869171Z","shell.execute_reply":"2023-12-13T19:56:30.877083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating Byte-Pair Encoding tokenizer\nraw_tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\nraw_tokenizer.normalizer = normalizers.Sequence([normalizers.NFC()] + [normalizers.Lowercase()] if LOWERCASE else [])\nraw_tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\nspecial_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\ntrainer = trainers.BpeTrainer(vocab_size=VOCAB_SIZE, special_tokens=special_tokens)\ndataset = Dataset.from_pandas(test[['text']])\ndef train_corp_iter(): \n    for i in range(0, len(dataset), 1000):\n        yield dataset[i : i + 1000][\"text\"]\nraw_tokenizer.train_from_iterator(train_corp_iter(), trainer=trainer)\ntokenizer = PreTrainedTokenizerFast(\n    tokenizer_object=raw_tokenizer,\n    unk_token=\"[UNK]\",\n    pad_token=\"[PAD]\",\n    cls_token=\"[CLS]\",\n    sep_token=\"[SEP]\",\n    mask_token=\"[MASK]\",\n)\ntokenized_texts_test = []\n\nfor text in tqdm(test['text'].tolist()):\n    tokenized_texts_test.append(tokenizer.tokenize(text))\n\ntokenized_texts_train = []\n\nfor text in tqdm(train['text'].tolist()):\n    tokenized_texts_train.append(tokenizer.tokenize(text))","metadata":{"execution":{"iopub.status.busy":"2023-12-13T19:56:36.290300Z","iopub.execute_input":"2023-12-13T19:56:36.290656Z","iopub.status.idle":"2023-12-13T19:58:34.550304Z","shell.execute_reply.started":"2023-12-13T19:56:36.290630Z","shell.execute_reply":"2023-12-13T19:58:34.549274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dummy(text):\n    return text\nvectorizer = TfidfVectorizer(ngram_range=(3, 5), lowercase=False, sublinear_tf=True, analyzer = 'word',\n    tokenizer = dummy,\n    preprocessor = dummy,\n    token_pattern = None, strip_accents='unicode')\n\nvectorizer.fit(tokenized_texts_test)\n\n# Getting vocab\nvocab = vectorizer.vocabulary_\n\nprint(vocab)\n\nvectorizer = TfidfVectorizer(ngram_range=(3, 5), lowercase=False, sublinear_tf=True, vocabulary=vocab,\n                            analyzer = 'word',\n                            tokenizer = dummy,\n                            preprocessor = dummy,\n                            token_pattern = None, strip_accents='unicode'\n                            )\n\ntf_train = vectorizer.fit_transform(tokenized_texts_train)\ntf_test = vectorizer.transform(tokenized_texts_test)\n\ndel vectorizer\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-12-13T19:58:34.552338Z","iopub.execute_input":"2023-12-13T19:58:34.552749Z","iopub.status.idle":"2023-12-13T20:02:52.372050Z","shell.execute_reply.started":"2023-12-13T19:58:34.552712Z","shell.execute_reply":"2023-12-13T20:02:52.371116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = train['label'].values","metadata":{"execution":{"iopub.status.busy":"2023-12-13T20:02:52.373246Z","iopub.execute_input":"2023-12-13T20:02:52.373525Z","iopub.status.idle":"2023-12-13T20:02:52.378317Z","shell.execute_reply.started":"2023-12-13T20:02:52.373501Z","shell.execute_reply":"2023-12-13T20:02:52.377361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FLAG = True if len(test.text.values) <= 5 else False\n\nif FLAG:\n    sub.to_csv('submission.csv', index=False)\nelse:\n    clf = MultinomialNB(alpha=0.02)\n    sgd_model = SGDClassifier(max_iter=8000, tol=1e-4, loss=\"modified_huber\") \n    lgb_params = {\n        'n_iter': 1500,\n        'verbose': -1,\n        'objective': 'binary',\n        'metric': 'auc',\n        'learning_rate': 0.05073909898961407,\n        'colsample_bytree': 0.726023996436955,\n        'colsample_bynode': 0.5803681307354022,\n        'lambda_l1': 8.562963348932286, \n        'lambda_l2': 4.893256185259296,\n        'min_data_in_leaf': 115,\n        'max_depth': 23,\n        'max_bin': 898\n    }\n    lgb = LGBMClassifier(**lgb_params)\n    cat = CatBoostClassifier(\n        iterations=1000,\n        verbose=0,\n        l2_leaf_reg=6.6591278779517808,\n        learning_rate=0.005689066836106983,\n        allow_const_label=True,\n        loss_function = 'CrossEntropy'\n)\n    weights = [0.07, 0.31, 0.31, 0.31]\n \n    ensemble = VotingClassifier(\n        estimators=[\n            ('mnb',clf),\n            ('sgd', sgd_model),\n            ('lgb',lgb), \n            ('cat', cat)\n        ],\n        weights=weights, \n        voting='soft',\n        n_jobs=-1\n    )\n    ensemble.fit(tf_train, y_train)\n    gc.collect()\n    final_preds = ensemble.predict_proba(tf_test)[:,1]\n    sub['generated'] = final_preds\n    sub.to_csv('submission.csv', index=False)\n    sub","metadata":{"execution":{"iopub.status.busy":"2023-12-13T20:39:09.544489Z","iopub.execute_input":"2023-12-13T20:39:09.545503Z","iopub.status.idle":"2023-12-13T20:39:09.559026Z","shell.execute_reply.started":"2023-12-13T20:39:09.545454Z","shell.execute_reply":"2023-12-13T20:39:09.557760Z"},"trusted":true},"execution_count":null,"outputs":[]}]}