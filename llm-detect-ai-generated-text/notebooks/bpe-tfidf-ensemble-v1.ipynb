{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":61542,"databundleVersionId":6888007,"sourceType":"competition"},{"sourceId":6977472,"sourceType":"datasetVersion","datasetId":4005256}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys, gc, os\n\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nimport numpy as np\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom tokenizers import (\n    decoders,\n    models,\n    normalizers,\n    pre_tokenizers,\n    processors,\n    trainers,\n    Tokenizer,\n)\n\nfrom datasets import Dataset\nfrom tqdm.auto import tqdm\nfrom transformers import PreTrainedTokenizerFast\n\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import VotingClassifier","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:15:48.279012Z","iopub.execute_input":"2023-12-15T02:15:48.279840Z","iopub.status.idle":"2023-12-15T02:16:00.084632Z","shell.execute_reply.started":"2023-12-15T02:15:48.279797Z","shell.execute_reply":"2023-12-15T02:16:00.083063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read data depending on whether it is on kaggle, colab or local\nif \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ:\n    print(\"Running on Kaggle!\")\n    kernel = 'kaggle'\n    test = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\n    submission = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv')\n    org_train = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_essays.csv')\n    extra = pd.read_csv(\"/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\", sep=',')\nelif \"google.colab\" in sys.modules:\n    print(\"Running on Google Colab!\")\n    kernel = 'google_colab'\n    from google.colab import drive\n    drive.mount('/content/drive')\n    data_path = '/content/drive/MyDrive/Kaggle/LLM_Detect_AI_Generated_Text/data/'\n    test = pd.read_csv(data_path + \"test_essays.csv\")\n    submission = pd.read_csv(data_path + \"sample_submission.csv\")\n    org_train = pd.read_csv(data_path + \"train_essays.csv\")\n    extra = pd.read_csv(data_path + \"train_v2_drcat_02.csv\", sep=\",\")\nelse:\n    print(\"Running locally.\")\n    kernel = 'local'\n    test = pd.read_csv(\"./data/test_essays.csv\")\n    submission = pd.read_csv(\"./data/sample_submission.csv\")\n    org_train = pd.read_csv(\"./data/train_essays.csv\")\n    train = pd.read_csv(\"./data/train_v2_drcat_02.csv\", sep=\",\")","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:25:28.123885Z","iopub.execute_input":"2023-12-15T02:25:28.124427Z","iopub.status.idle":"2023-12-15T02:25:29.432646Z","shell.execute_reply.started":"2023-12-15T02:25:28.124385Z","shell.execute_reply":"2023-12-15T02:25:29.431117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop duplicates\nextra = extra.drop_duplicates(subset=['text'])\nextra.reset_index(drop=True, inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:25:29.434960Z","iopub.execute_input":"2023-12-15T02:25:29.435395Z","iopub.status.idle":"2023-12-15T02:25:29.522498Z","shell.execute_reply.started":"2023-12-15T02:25:29.435354Z","shell.execute_reply":"2023-12-15T02:25:29.521133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train, val, test set 90%, 10%, 10% respectively\nextra = extra.sample(frac=1.0, random_state=42).reset_index(drop=True)\nX, y = extra['text'], extra['label']\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\nprint(f\"Train set size: {len(X_train)}\")\nprint(f\"Validation set size: {len(X_val)}\")\nprint(f\"Test set size: {len(X_test)}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:25:30.306181Z","iopub.execute_input":"2023-12-15T02:25:30.306585Z","iopub.status.idle":"2023-12-15T02:25:30.324665Z","shell.execute_reply.started":"2023-12-15T02:25:30.306555Z","shell.execute_reply":"2023-12-15T02:25:30.322889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LOWERCASE, VOCAB_SIZE = False, 30522","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:25:42.085266Z","iopub.execute_input":"2023-12-15T02:25:42.085700Z","iopub.status.idle":"2023-12-15T02:25:42.091893Z","shell.execute_reply.started":"2023-12-15T02:25:42.085669Z","shell.execute_reply":"2023-12-15T02:25:42.090674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating Byte-Pair Encoding tokenizer\nraw_tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\nraw_tokenizer.normalizer = normalizers.Sequence([normalizers.NFC()] + [normalizers.Lowercase()] if LOWERCASE else [])\nraw_tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\nspecial_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\ntrainer = trainers.BpeTrainer(vocab_size=VOCAB_SIZE, special_tokens=special_tokens)\ndataset = Dataset.from_pandas(pd.DataFrame(X_test))\n\ndef train_corp_iter(): \n    for i in range(0, len(dataset), 1000):\n        yield dataset[i : i + 1000][\"text\"]\n\nraw_tokenizer.train_from_iterator(train_corp_iter(), trainer=trainer)\ntokenizer = PreTrainedTokenizerFast(\n    tokenizer_object=raw_tokenizer,\n    unk_token=\"[UNK]\",\n    pad_token=\"[PAD]\",\n    cls_token=\"[CLS]\",\n    sep_token=\"[SEP]\",\n    mask_token=\"[MASK]\",\n)\n\ntokenized_texts_test, tokenized_texts_train = [], []\n\nfor text in tqdm(X_test.tolist()):\n    tokenized_texts_test.append(tokenizer.tokenize(text))\nfor text in tqdm(X_train.tolist()):\n    tokenized_texts_train.append(tokenizer.tokenize(text))","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:25:42.336409Z","iopub.execute_input":"2023-12-15T02:25:42.337222Z","iopub.status.idle":"2023-12-15T02:25:42.492379Z","shell.execute_reply.started":"2023-12-15T02:25:42.337173Z","shell.execute_reply":"2023-12-15T02:25:42.490757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dummy(text):\n    return text\n\n\ntfidf_params = {\n    \"ngram_range\": (3, 5),\n    \"lowercase\": False,\n    \"sublinear_tf\": True,\n    \"analyzer\": \"word\",\n    \"tokenizer\": dummy,\n    \"preprocessor\": dummy,\n    \"token_pattern\": None,\n    \"strip_accents\": \"unicode\",\n}\n\n# learn TF-IDF vocabulary on test set\nvectorizer = TfidfVectorizer(**tfidf_params)\nvectorizer.fit(tokenized_texts_test)\nvocab = vectorizer.vocabulary_\n# print(f\"Test dataset TF-IDF vocabulary: {vocab}\")\n\n# fit TF-IDF on train set using only vocaulary learned from test set\nvectorizer = TfidfVectorizer(**tfidf_params)\ntf_train = vectorizer.fit_transform(tokenized_texts_train)\ntf_test = vectorizer.transform(tokenized_texts_test)\ndel vectorizer\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:25:43.617839Z","iopub.execute_input":"2023-12-15T02:25:43.618377Z","iopub.status.idle":"2023-12-15T02:25:44.268734Z","shell.execute_reply.started":"2023-12-15T02:25:43.618337Z","shell.execute_reply":"2023-12-15T02:25:44.266695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = MultinomialNB(alpha=0.02)\nsgd_model = SGDClassifier(max_iter=8000, tol=1e-4, loss=\"modified_huber\") \nlgb_params = {\n    'n_iter': 1500,\n    'verbose': -1,\n    'objective': 'binary',\n    'metric': 'auc',\n    'learning_rate': 0.05073909898961407,\n    'colsample_bytree': 0.726023996436955,\n    'colsample_bynode': 0.5803681307354022,\n    'lambda_l1': 8.562963348932286, \n    'lambda_l2': 4.893256185259296,\n    'min_data_in_leaf': 115,\n    'max_depth': 23,\n    'max_bin': 898\n}\nlgb = LGBMClassifier(**lgb_params)\ncat = CatBoostClassifier(\n    iterations=1000,\n    verbose=0,\n    l2_leaf_reg=6.6591278779517808,\n    learning_rate=0.005689066836106983,\n    allow_const_label=True,\n    loss_function = 'CrossEntropy'\n)\nweights = [0.07, 0.31, 0.31, 0.31]\n\nensemble = VotingClassifier(\n    estimators=[\n        ('mnb',clf),\n        ('sgd', sgd_model),\n        ('lgb',lgb), \n        ('cat', cat)\n    ],\n    weights=weights, \n    voting='soft',\n    n_jobs=-1\n)\nensemble.fit(tf_train, y_train)\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:25:46.211389Z","iopub.execute_input":"2023-12-15T02:25:46.212300Z","iopub.status.idle":"2023-12-15T02:28:15.678643Z","shell.execute_reply.started":"2023-12-15T02:25:46.212255Z","shell.execute_reply":"2023-12-15T02:28:15.676909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\n\ndef evaluate_model_predictions(model, X, y, set_name):\n    predictions = model.predict(X)\n    proba = model.predict_proba(X)[:, 1]\n    auc = roc_auc_score(y, proba)\n\n    print(f\"{set_name} Set Evaluation:\")\n    print(f\"AUC: {auc}\")\n    print(\"\\nClassification Report:\")\n    print(classification_report(y, predictions))\n    print(\"\\nConfusion Matrix:\")\n    print(confusion_matrix(y, predictions))\n    print(\"\\n\\n\")\n\nevaluate_model_predictions(ensemble, tf_train, y_train, \"Training\")\nevaluate_model_predictions(ensemble, tf_test, y_test, \"Testing\")","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:28:30.202652Z","iopub.execute_input":"2023-12-15T02:28:30.203186Z","iopub.status.idle":"2023-12-15T02:28:30.490821Z","shell.execute_reply.started":"2023-12-15T02:28:30.203147Z","shell.execute_reply":"2023-12-15T02:28:30.489065Z"},"trusted":true},"execution_count":null,"outputs":[]}]}