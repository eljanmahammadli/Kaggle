{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T02:16:24.294406Z","iopub.status.busy":"2023-12-15T02:16:24.294152Z","iopub.status.idle":"2023-12-15T02:16:32.767082Z","shell.execute_reply":"2023-12-15T02:16:32.765726Z","shell.execute_reply.started":"2023-12-15T02:16:24.294382Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'seaborn'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m/Users/elcan/Documents/Code/Kaggle/llm-detect-ai-generated-text/notebooks/bert-fine-tuning-v1-inference.ipynb Cell 1\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/elcan/Documents/Code/Kaggle/llm-detect-ai-generated-text/notebooks/bert-fine-tuning-v1-inference.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/elcan/Documents/Code/Kaggle/llm-detect-ai-generated-text/notebooks/bert-fine-tuning-v1-inference.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/elcan/Documents/Code/Kaggle/llm-detect-ai-generated-text/notebooks/bert-fine-tuning-v1-inference.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/elcan/Documents/Code/Kaggle/llm-detect-ai-generated-text/notebooks/bert-fine-tuning-v1-inference.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m stopwords\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/elcan/Documents/Code/Kaggle/llm-detect-ai-generated-text/notebooks/bert-fine-tuning-v1-inference.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnltk\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"]}],"source":["import os, sys, re, gc, time, tqdm\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from nltk.corpus import stopwords\n","import nltk\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n","from datasets import Dataset\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset, random_split\n","from torch.nn.parallel import DataParallel\n","import pandas as pd\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T02:16:50.954112Z","iopub.status.busy":"2023-12-15T02:16:50.953024Z","iopub.status.idle":"2023-12-15T02:16:53.009861Z","shell.execute_reply":"2023-12-15T02:16:53.009104Z","shell.execute_reply.started":"2023-12-15T02:16:50.954074Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on Kaggle!\n"]}],"source":["# read data depending on whether it is on kaggle, colab or local\n","if \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ:\n","    print(\"Running on Kaggle!\")\n","    kernel = 'kaggle'\n","    test = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\n","    submission = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv')\n","    org_train = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_essays.csv')\n","    extra = pd.read_csv(\"/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\", sep=',')\n","elif \"google.colab\" in sys.modules:\n","    print(\"Running on Google Colab!\")\n","    kernel = 'google_colab'\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    data_path = '/content/drive/MyDrive/Kaggle/LLM_Detect_AI_Generated_Text/data/'\n","    test = pd.read_csv(data_path + \"test_essays.csv\")\n","    submission = pd.read_csv(data_path + \"sample_submission.csv\")\n","    org_train = pd.read_csv(data_path + \"train_essays.csv\")\n","    extra = pd.read_csv(data_path + \"train_v2_drcat_02.csv\", sep=\",\")\n","else:\n","    print(\"Running locally.\")\n","    kernel = 'local'\n","    test = pd.read_csv(\"./data/test_essays.csv\")\n","    submission = pd.read_csv(\"./data/sample_submission.csv\")\n","    org_train = pd.read_csv(\"./data/train_essays.csv\")\n","    train = pd.read_csv(\"./data/train_v2_drcat_02.csv\", sep=\",\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T02:16:53.140750Z","iopub.status.busy":"2023-12-15T02:16:53.140430Z","iopub.status.idle":"2023-12-15T02:17:03.222120Z","shell.execute_reply":"2023-12-15T02:17:03.221279Z","shell.execute_reply.started":"2023-12-15T02:16:53.140723Z"},"trusted":true},"outputs":[],"source":["# drop duplicates\n","extra = extra.drop_duplicates(subset=['text'])\n","extra.reset_index(drop=True, inplace=True)\n","\n","# Text Preprocessing\n","stop_words = set(stopwords.words('english'))\n","\n","def clean_text(text):\n","    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuations\n","    words = text.split()  # Tokenize\n","    words = [word.lower() for word in words if word.isalpha()]  # Lowercase and remove non-alphabetic words\n","    words = [word for word in words if word not in stop_words]  # Remove stop words\n","    return ' '.join(words)\n","\n","extra['clean_text'] = extra['text'].apply(clean_text)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T02:17:03.223960Z","iopub.status.busy":"2023-12-15T02:17:03.223668Z","iopub.status.idle":"2023-12-15T02:17:03.293879Z","shell.execute_reply":"2023-12-15T02:17:03.292991Z","shell.execute_reply.started":"2023-12-15T02:17:03.223935Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train set size: 35894\n","Validation set size: 4487\n","Test set size: 4487\n"]}],"source":["# train, val, test set 90%, 10%, 10% respectively\n","extra = extra.sample(frac=1.0, random_state=42).reset_index(drop=True)\n","X, y = extra['clean_text'], extra['label']\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n","print(f\"Train set size: {len(X_train)}\")\n","print(f\"Validation set size: {len(X_val)}\")\n","print(f\"Test set size: {len(X_test)}\")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T02:17:03.295512Z","iopub.status.busy":"2023-12-15T02:17:03.295159Z","iopub.status.idle":"2023-12-15T02:17:10.658630Z","shell.execute_reply":"2023-12-15T02:17:10.657716Z","shell.execute_reply.started":"2023-12-15T02:17:03.295476Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd5b5abdae26490e92cd25f1af3dffb9","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.30k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"778e74a6d66a4860886bc0f74676e563","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"be929d1ec6c54d2cb5e83a81a041b74d","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f63d7dc7efbb4a3dba4fe6cb504eab03","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fd4d54202f16497499df8e5fe091529e","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["cuda\n"]},{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer = BertTokenizer.from_pretrained(\"eljanmahammadli/bert-base-uncased-llm-detect-ai\")\n","model = BertForSequenceClassification.from_pretrained(\"eljanmahammadli/bert-base-uncased-llm-detect-ai\")\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","model.to(device)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T02:17:10.661483Z","iopub.status.busy":"2023-12-15T02:17:10.661106Z","iopub.status.idle":"2023-12-15T02:20:01.308002Z","shell.execute_reply":"2023-12-15T02:20:01.307199Z","shell.execute_reply.started":"2023-12-15T02:17:10.661440Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader, TensorDataset\n","\n","# Assuming your tokenizer and model are already defined and loaded\n","\n","# Convert test data into a PyTorch Dataset\n","test_encodings = tokenizer(X_test.tolist(), padding=True, truncation=True, return_tensors='pt')\n","test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'])\n","\n","# Create a DataLoader for your test set\n","batch_size = 100  # You can adjust this depending on your GPU memory\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Function to predict in batches\n","def predict(model, dataloader):\n","    model.eval()  # Set model to evaluation mode\n","    predictions = []\n","\n","    with torch.no_grad():\n","        for batch in tqdm.tqdm(dataloader):\n","            input_ids, attention_mask = [b.to(device) for b in batch]\n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            logits = outputs.logits\n","            batch_predictions = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()\n","            predictions.extend(batch_predictions)\n","\n","    return predictions\n","\n","# Generate predictions\n","predictions = predict(model, test_loader)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T02:20:01.309472Z","iopub.status.busy":"2023-12-15T02:20:01.309185Z","iopub.status.idle":"2023-12-15T02:20:01.322847Z","shell.execute_reply":"2023-12-15T02:20:01.321944Z","shell.execute_reply.started":"2023-12-15T02:20:01.309447Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["AUC-ROC on Validation Data: 0.9998\n"]}],"source":["from sklearn.metrics import roc_auc_score\n","test_auc_roc = roc_auc_score(y_test, predictions)\n","print(f\"AUC-ROC on Validation Data: {test_auc_roc:.4f}\")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T02:20:01.324162Z","iopub.status.busy":"2023-12-15T02:20:01.323843Z","iopub.status.idle":"2023-12-15T02:20:01.365209Z","shell.execute_reply":"2023-12-15T02:20:01.364320Z","shell.execute_reply.started":"2023-12-15T02:20:01.324138Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Confusion Matrix:\n","[[2718   19]\n"," [  11 1739]]\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99      2737\n","           1       0.99      0.99      0.99      1750\n","\n","    accuracy                           0.99      4487\n","   macro avg       0.99      0.99      0.99      4487\n","weighted avg       0.99      0.99      0.99      4487\n","\n"]}],"source":["from sklearn.metrics import confusion_matrix, classification_report\n","import numpy as np\n","\n","# Convert probabilities to class predictions\n","# Assuming predictions is a list of probabilities for the positive class\n","threshold = 0.5\n","class_predictions = [1 if prob > threshold else 0 for prob in predictions]\n","\n","# Convert y_test to a list if it is not already\n","y_test_list = list(y_test)\n","\n","# Calculate the confusion matrix\n","conf_matrix = confusion_matrix(y_test_list, class_predictions)\n","\n","# Calculate the classification report\n","class_report = classification_report(y_test_list, class_predictions)\n","\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n","\n","print(\"\\nClassification Report:\")\n","print(class_report)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T01:41:58.510174Z","iopub.status.busy":"2023-12-15T01:41:58.509180Z","iopub.status.idle":"2023-12-15T01:41:58.553641Z","shell.execute_reply":"2023-12-15T01:41:58.552502Z","shell.execute_reply.started":"2023-12-15T01:41:58.510125Z"},"trusted":true},"outputs":[],"source":["# Test data processing\n","test_inputs = tokenizer(test['text'].tolist(), padding=True, truncation=True, return_tensors='pt')\n","\n","# Move input tensor to the same device as the model\n","test_inputs = {key: value.to(device) for key, value in test_inputs.items()}\n","\n","# Generate predictions using your trained model\n","with torch.no_grad():\n","    outputs = model(**test_inputs)\n","    logits = outputs.logits\n","\n","# Assuming the first column of logits corresponds to the negative class (non-AI-generated)\n","# and the second column corresponds to the positive class (AI-generated)\n","predictions = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()  # Move predictions back to CPU\n","\n","# Create a submission DataFrame with essay IDs and corresponding predictions\n","submission = pd.DataFrame({\n","    'id': test['id'],\n","    'generated': predictions\n","})\n","\n","\n","submission.to_csv('/kaggle/working/submission.csv', index=False)\n","print(submission)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T01:45:52.662150Z","iopub.status.busy":"2023-12-15T01:45:52.661463Z","iopub.status.idle":"2023-12-15T01:45:53.095906Z","shell.execute_reply":"2023-12-15T01:45:53.094742Z","shell.execute_reply.started":"2023-12-15T01:45:52.662114Z"},"trusted":true},"outputs":[],"source":["#  del model\n","# del test_inputs\n","# torch.cuda.empty_cache()\n","gc.collect()"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":6888007,"sourceId":61542,"sourceType":"competition"},{"datasetId":4005256,"sourceId":6977472,"sourceType":"datasetVersion"}],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
